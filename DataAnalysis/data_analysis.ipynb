{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_analysis.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jShfRbPGaU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "517d56fd-0f08-4ae1-885d-7f4b025aaf1d"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from elasticsearch import Elasticsearch\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "def compute_sentiment(review_text: str):\n",
        "    sentiment = ''\n",
        "    compound_score = sia.polarity_scores(review_text)[\"compound\"]\n",
        "    if compound_score < -0.25 :\n",
        "      sentiment = 'negative'\n",
        "    elif compound_score >= -0.25 and compound_score <= 0.25:\n",
        "      sentiment = 'neutral'\n",
        "    else:\n",
        "      sentiment = 'positive'\n",
        "    return sentiment\n",
        "\n",
        "def read_data(filename):\n",
        "  input_data = pd.read_csv(filename)\n",
        "  input_data = input_data.fillna('.')\n",
        "  return input_data\n",
        "\n",
        "def populate_dictionary(scores_aggregate):\n",
        "  s = set({1, 2, 3, 4, 5})\n",
        "  for number in s :\n",
        "    if number not in scores_aggregate.keys():\n",
        "      scores_aggregate[number] = 0\n",
        "\n",
        "def calculate_scores():\n",
        "  input_data = read_data('sample_data.csv')\n",
        "  array_scores = input_data['How comfortable are you working with arrays?']\n",
        "  pointer_scores = input_data['How comfortable are you working with pointers?']\n",
        "  linked_list_scores = input_data['How comfortable are you working with Linked Lists?']\n",
        "  ta_ratings = input_data['How would you rate your TA?']\n",
        "  recitation_text = input_data['If you could improve one thing about Recitation, what would it be?']\n",
        "  array_scores_aggregate = Counter(array_scores)\n",
        "  linked_list_scores_aggregate = Counter(linked_list_scores)\n",
        "  pointer_scores_aggregate = Counter(pointer_scores)\n",
        "  populate_dictionary(array_scores_aggregate)\n",
        "  populate_dictionary(pointer_scores_aggregate)\n",
        "  populate_dictionary(linked_list_scores_aggregate)\n",
        "  agg = ta_ratings.agg(['min', 'max', 'average'])\n",
        "  ta_max_rating = round((float) (agg['max']), 2)\n",
        "  ta_min_rating = round((float) (agg['min']), 2)\n",
        "  ta_average_rating =  round((float) (agg['average']), 2)\n",
        "  ta_scores = {\"ta_max_rating\" : ta_max_rating, \"ta_min_rating\" :ta_min_rating, \"ta_average_rating\" : ta_average_rating}\n",
        "  polarity_dictionary = {} \n",
        "  for text in recitation_text:\n",
        "    sentiment = compute_sentiment(text)\n",
        "    polarity_dictionary[sentiment] = polarity_dictionary.get(sentiment, 0) + 1\n",
        "    \n",
        "  return [array_scores_aggregate, pointer_scores_aggregate, linked_list_scores_aggregate, ta_scores, polarity_dictionary]\n",
        "\n",
        "def main():\n",
        "  scores = calculate_scores()\n",
        "  array_scores_aggregate, pointer_scores_aggregate, linked_list_scores_aggregate, ta_scores, polarity_dictionary = scores[0], scores[1], scores[2], scores[3], scores[4]\n",
        "  print('array scores {}'.format(array_scores_aggregate))\n",
        "  print('pointer scores {}'.format(pointer_scores_aggregate))\n",
        "  print('linked list scores {}'.format(linked_list_scores_aggregate))\n",
        "  print('TA Scores {}' .format(ta_scores))\n",
        "  print('Polarity Dictionary {}' .format(polarity_dictionary))\n",
        "  return array_scores_aggregate, pointer_scores_aggregate, linked_list_scores_aggregate, ta_scores, polarity_dictionary\n",
        "\n",
        "def get_es_credentials():\n",
        "  return {\n",
        "      \"user\": \"elastic\", \n",
        "      \"password\": \"s5B0DDHP35MTfvYLvnPx1afX\",\n",
        "      \"cloud_id\": \"fos-project:dXMtd2VzdDEuZ2NwLmNsb3VkLmVzLmlvJGYwYjZlYzVhYzlkNTQ3ZmY5NWQ3Yjg0YmNlN2Q5MDM1JDFhNWMyNzBlYzk1NjQwOGQ5ZGM4MTUxMjMyNDdhMWM0\"\n",
        "    }\n",
        "\n",
        "ELASTIC_SETTINGS = get_es_credentials()\n",
        "\n",
        "def es(array_scores_aggregate, pointer_scores_aggregate, linked_list_scores_aggregate, ta_scores, polarity_dictionary):\n",
        "  es = Elasticsearch(\n",
        "      cloud_id=ELASTIC_SETTINGS[\"cloud_id\"],\n",
        "      http_auth=(ELASTIC_SETTINGS[\"user\"], ELASTIC_SETTINGS[\"password\"]),\n",
        "  )\n",
        "  \n",
        "  #ta_scores = {\"ta_max_rating\" : ta_max_rating, \"ta_min_rating\" :ta_min_rating, \"ta_average_rating\" : ta_average_rating}\n",
        "  es.index(index='sw', doc_type='people', id=1, body= array_scores_aggregate)\n",
        "  es.index(index='sw', doc_type='people', id=2, body= pointer_scores_aggregate)\n",
        "  es.index(index='sw', doc_type='people', id=3, body= linked_list_scores_aggregate)\n",
        "  es.index(index='sw', doc_type='people', id=4, body= ta_scores)\n",
        "  es.index(index='sw', doc_type='people', id=5, body= polarity_dictionary)\n",
        "\n",
        "  array_scores_1 = es.get(index='sw', doc_type='people', id=1)\n",
        "  pointer_scores_1 = es.get(index='sw', doc_type='people', id=2)\n",
        "  linked_list_scores_1 = es.get(index='sw', doc_type='people', id=3)\n",
        "  ta_scores_1 = es.get(index='sw', doc_type='people', id=4)\n",
        "  polarity_dictionary_1 = es.get(index='sw', doc_type='people', id=5)\n",
        "\n",
        "\n",
        "  print(array_scores_1)\n",
        "  print(pointer_scores_1)\n",
        "  print(linked_list_scores_1)\n",
        "  print(ta_scores_1)\n",
        "  print(polarity_dictionary_1)\n",
        "\n",
        "array_scores_aggregate, pointer_scores_aggregate, linked_list_scores_aggregate, ta_scores, polarity_dictionary = main()\n",
        "print()\n",
        "array_scores_aggregate = { \"array_\"+str(k): v for k, v in array_scores_aggregate.items() }\n",
        "pointer_scores_aggregate = { \"pointer_\"+str(k): v for k, v in pointer_scores_aggregate.items() }\n",
        "linked_list_scores_aggregate = { \"linkedlist_\"+str(k): v for k, v in linked_list_scores_aggregate.items() }\n",
        "\n",
        "es(array_scores_aggregate, pointer_scores_aggregate, linked_list_scores_aggregate, ta_scores, polarity_dictionary)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "array scores Counter({5: 14, 4: 8, 3: 6, 1: 0, 2: 0})\n",
            "pointer scores Counter({4: 15, 3: 7, 5: 5, 1: 1, 2: 0})\n",
            "linked list scores Counter({3: 10, 4: 10, 5: 5, 2: 2, 1: 1})\n",
            "TA Scores {'ta_max_rating': 5.0, 'ta_min_rating': 3.0, 'ta_average_rating': 4.68}\n",
            "Polarity Dictionary {'positive': 12, 'neutral': 15, 'negative': 1}\n",
            "\n",
            "{'_index': 'sw', '_type': 'people', '_id': '1', '_version': 17, '_seq_no': 72, '_primary_term': 1, 'found': True, '_source': {'array_5': 14, 'array_3': 6, 'array_4': 8, 'array_1': 0, 'array_2': 0}}\n",
            "{'_index': 'sw', '_type': 'people', '_id': '2', '_version': 16, '_seq_no': 73, '_primary_term': 1, 'found': True, '_source': {'pointer_5': 5, 'pointer_4': 15, 'pointer_1': 1, 'pointer_3': 7, 'pointer_2': 0}}\n",
            "{'_index': 'sw', '_type': 'people', '_id': '3', '_version': 16, '_seq_no': 74, '_primary_term': 1, 'found': True, '_source': {'linkedlist_5': 5, 'linkedlist_3': 10, 'linkedlist_4': 10, 'linkedlist_1': 1, 'linkedlist_2': 2}}\n",
            "{'_index': 'sw', '_type': 'people', '_id': '4', '_version': 15, '_seq_no': 75, '_primary_term': 1, 'found': True, '_source': {'ta_max_rating': 5.0, 'ta_min_rating': 3.0, 'ta_average_rating': 4.68}}\n",
            "{'_index': 'sw', '_type': 'people', '_id': '5', '_version': 13, '_seq_no': 76, '_primary_term': 1, 'found': True, '_source': {'positive': 12, 'neutral': 15, 'negative': 1}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}